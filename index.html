<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8">
  <title>音声分析ビューワー</title>
  <style>
    body {
      background: #222;
      color: white;
      font-family: sans-serif;
      padding: 20px;
    }
    canvas {
      width: 100%;
      height: 200px;
      background: #000;
      margin: 10px 0;
    }
    .controls {
      margin: 10px 0;
    }
    input[type="range"] {
      width: 100%;
    }
  </style>
</head>
<body>
  <h2>🎧 音声左右分離・波形＆スペクトログラム表示</h2>
  <input type="file" id="fileInput" accept="video/mp4,audio/wav" />
  <div class="controls">
    <button id="play">▶ 再生</button>
    <input type="range" id="seekBar" min="0" max="1" step="0.001" value="0">
  </div>

  <h3>🔊 左チャンネル（波形）</h3>
  <canvas id="leftCanvas" width="800" height="200"></canvas>
  <h3>🔊 左チャンネル（スペクトログラム）</h3>
  <canvas id="leftSpec" width="800" height="200"></canvas>
  <label>音量：<input type="range" id="leftVolume" min="0" max="1" step="0.01" value="1"></label>

  <h3>🔊 右チャンネル（波形）</h3>
  <canvas id="rightCanvas" width="800" height="200"></canvas>
  <h3>🔊 右チャンネル（スペクトログラム）</h3>
  <canvas id="rightSpec" width="800" height="200"></canvas>
  <label>音量：<input type="range" id="rightVolume" min="0" max="1" step="0.01" value="1"></label>

  <script>
    const fileInput = document.getElementById("fileInput");
    const playButton = document.getElementById("play");
    const seekBar = document.getElementById("seekBar");
    const leftCanvas = document.getElementById("leftCanvas");
    const rightCanvas = document.getElementById("rightCanvas");
    const leftSpec = document.getElementById("leftSpec");
    const rightSpec = document.getElementById("rightSpec");
    const leftCtx = leftCanvas.getContext("2d");
    const rightCtx = rightCanvas.getContext("2d");
    const leftSpecCtx = leftSpec.getContext("2d");
    const rightSpecCtx = rightSpec.getContext("2d");
    const leftVolume = document.getElementById("leftVolume");
    const rightVolume = document.getElementById("rightVolume");

    let audioContext = new (window.AudioContext || window.webkitAudioContext)();
    let leftBuffer = null;
    let rightBuffer = null;
    let startTime = 0;
    let pauseOffset = 0;
    let duration = 0;
    let playing = false;

    let leftGainNode, rightGainNode;
    let leftAnalyser, rightAnalyser;
    let leftSource, rightSource;

    fileInput.addEventListener("change", async (e) => {
      const file = e.target.files[0];
      if (!file) return;

      const arrayBuffer = await file.arrayBuffer();
      const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);

      if (audioBuffer.numberOfChannels < 2) {
        alert("ステレオ音声ではありません！");
        return;
      }

      const leftData = audioBuffer.getChannelData(0);
      const rightData = audioBuffer.getChannelData(1);

      leftBuffer = audioContext.createBuffer(1, leftData.length, audioBuffer.sampleRate);
      rightBuffer = audioContext.createBuffer(1, rightData.length, audioBuffer.sampleRate);
      leftBuffer.copyToChannel(leftData, 0);
      rightBuffer.copyToChannel(rightData, 0);

      duration = leftBuffer.duration;
      seekBar.max = duration;

      drawWaveform(leftCtx, leftData, "lime");
      drawWaveform(rightCtx, rightData, "aqua");

      alert("読み込み完了！");
    });

    playButton.addEventListener("click", () => {
      if (!leftBuffer || !rightBuffer) return alert("ファイルを読み込んでください");

      if (playing) {
        stopPlayback();
        playButton.textContent = "▶ 再生";
      } else {
        startPlayback(pauseOffset);
        playButton.textContent = "⏸ 一時停止";
      }
    });

    function startPlayback(offset) {
      leftSource = audioContext.createBufferSource();
      rightSource = audioContext.createBufferSource();
      leftSource.buffer = leftBuffer;
      rightSource.buffer = rightBuffer;

      leftGainNode = audioContext.createGain();
      rightGainNode = audioContext.createGain();
      leftGainNode.gain.value = parseFloat(leftVolume.value);
      rightGainNode.gain.value = parseFloat(rightVolume.value);

      leftAnalyser = audioContext.createAnalyser();
      rightAnalyser = audioContext.createAnalyser();
      leftAnalyser.fftSize = 256;
      rightAnalyser.fftSize = 256;

      const merger = audioContext.createChannelMerger(2);
      leftSource.connect(leftGainNode).connect(leftAnalyser).connect(merger, 0, 0);
      rightSource.connect(rightGainNode).connect(rightAnalyser).connect(merger, 0, 1);
      merger.connect(audioContext.destination);

      startTime = audioContext.currentTime - offset;
      leftSource.start(0, offset);
      rightSource.start(0, offset);
      playing = true;

      requestAnimationFrame(updateSeekBar);
      requestAnimationFrame(drawSpectrograms);

      leftSource.onended = stopPlayback;
    }

    function stopPlayback() {
      if (leftSource) leftSource.stop();
      if (rightSource) rightSource.stop();
      pauseOffset = audioContext.currentTime - startTime;
      playing = false;
      playButton.textContent = "▶ 再生";
    }

    function updateSeekBar() {
      if (!playing) return;
      const current = audioContext.currentTime - startTime;
      seekBar.value = current;
      if (current >= duration) {
        playing = false;
        playButton.textContent = "▶ 再生";
        return;
      }
      requestAnimationFrame(updateSeekBar);
    }

    seekBar.addEventListener("input", () => {
      if (playing) {
        stopPlayback();
        pauseOffset = parseFloat(seekBar.value);
        startPlayback(pauseOffset);
      } else {
        pauseOffset = parseFloat(seekBar.value);
      }
    });

    leftVolume.addEventListener("input", () => {
      if (leftGainNode) leftGainNode.gain.value = parseFloat(leftVolume.value);
    });

    rightVolume.addEventListener("input", () => {
      if (rightGainNode) rightGainNode.gain.value = parseFloat(rightVolume.value);
    });

    function drawWaveform(ctx, data, color) {
      const width = ctx.canvas.width;
      const height = ctx.canvas.height;
      ctx.clearRect(0, 0, width, height);
      ctx.beginPath();
      ctx.strokeStyle = color;
      const step = Math.floor(data.length / width);
      const amp = height / 2;

      for (let i = 0; i < width; i++) {
        let min = 1.0, max = -1.0;
        for (let j = 0; j < step; j++) {
          const val = data[i * step + j];
          if (val < min) min = val;
          if (val > max) max = val;
        }
        ctx.moveTo(i, amp - min * amp);
        ctx.lineTo(i, amp - max * amp);
      }

      ctx.stroke();
    }

    function drawSpectrograms() {
      if (!playing) return;
      drawSpec(leftAnalyser, leftSpecCtx);
      drawSpec(rightAnalyser, rightSpecCtx);
      requestAnimationFrame(drawSpectrograms);
    }

    function drawSpec(analyser, ctx) {
      const width = ctx.canvas.width;
      const height = ctx.canvas.height;
      const dataArray = new Uint8Array(analyser.frequencyBinCount);
      analyser.getByteFrequencyData(dataArray);

      const imageData = ctx.getImageData(1, 0, width - 1, height);
      ctx.putImageData(imageData, 0, 0);

      for (let i = 0; i < height; i++) {
        const value = dataArray[i];
        ctx.fillStyle = `hsl(${value}, 100%, 50%)`;
        ctx.fillRect(width - 1, height - i, 1, 1);
      }
    }
  </script>
</body>
</html>
